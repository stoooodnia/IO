{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import clear_output\n",
    "import json\n",
    "\n",
    "\n",
    "def getTweetsDaily(search, start_date, end_date, num):\n",
    "    tweets = []\n",
    "    start = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "    end = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
    "    timespan = (end - start).days\n",
    "    for i in range(timespan):\n",
    "        clear_output(wait=True)\n",
    "        start_date = start.strftime(\"%Y-%m-%d\")\n",
    "        end_date = (start + timedelta(1)).strftime(\"%Y-%m-%d\")\n",
    "        query = f\"{search} lang:pl -filter:links -filter:replies -PIC since:{start_date} until:{end_date}\"\n",
    "        for j, tweet in enumerate(\n",
    "            sntwitter.TwitterSearchScraper(query, maxEmptyPages=2).get_items()\n",
    "        ):\n",
    "            if j >= num:\n",
    "                break\n",
    "            tweets.append(\n",
    "                {\n",
    "                    \"date\": tweet.date.strftime(\"%Y-%m-%d, %H:%M:%S\"),\n",
    "                    \"id\": tweet.id,\n",
    "                    \"content\": tweet.rawContent,\n",
    "                }\n",
    "            )\n",
    "        print(\n",
    "            f\"Target tweets: {timespan} days * {num} tweets = {timespan * num}\\nDays left: {timespan-i-1}\\nCollected tweets: {len(tweets)}\"\n",
    "        )\n",
    "        start = start + timedelta(1)\n",
    "    return tweets\n",
    "\n",
    "\n",
    "def getTweets(search, start_date, end_date, num):\n",
    "    tweets = []\n",
    "    query = f\"{search} lang:pl -filter:links -filter:replies -PIC since:{start_date} until:{end_date}\"\n",
    "    for j, tweet in enumerate(\n",
    "        sntwitter.TwitterSearchScraper(query, maxEmptyPages=2).get_items()\n",
    "    ):\n",
    "        clear_output(wait=True)\n",
    "        if j >= num:\n",
    "            break\n",
    "        tweets.append(\n",
    "            {\n",
    "                \"date\": tweet.date.strftime(\"%Y-%m-%d, %H:%M:%S\"),\n",
    "                \"id\": tweet.id,\n",
    "                \"content\": tweet.rawContent.replace(\"\\n\", \" \"),\n",
    "            }\n",
    "        )\n",
    "        display(f\"Target tweets: {num} tweets\")\n",
    "        display(f\"Collected tweets: {len(tweets)}\")\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Target tweets: 10000 tweets'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Collected tweets: 10000'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matura21 = getTweets(\n",
    "    \"matura OR #matura21 OR #Matura2021 OR #matura2021 OR matura2021\",\n",
    "    \"2021-04-01\",\n",
    "    \"2021-06-30\",\n",
    "    10000,\n",
    ")\n",
    "matura21_string = json.dumps(matura21, ensure_ascii=False)\n",
    "matura21File = open(\"matura21.json\", \"w\")\n",
    "matura21File.write(matura21_string)\n",
    "matura21File.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Target tweets: 10000 tweets'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Collected tweets: 10000'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matura22 = getTweets(\"matura OR #matura22 OR #Matura2022 OR #matura2022 OR matura2022\", \"2022-04-01\", \"2022-06-30\", 10000)\n",
    "matura22_str = json.dumps(matura22, ensure_ascii=False)\n",
    "matura22File = open(\"matura22.json\", \"w\")\n",
    "matura22File.write(matura22_str)\n",
    "matura22File.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Target tweets: 10000 tweets'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Collected tweets: 10000'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matura23 = getTweets(\"matura OR #matura23 OR #Matura2023 OR #matura2023 OR matura2023\", \"2023-01-01\", \"2023-06-30\", 10000)\n",
    "matura23_str = json.dumps(matura23, ensure_ascii=False)\n",
    "matura23File = open(\"matura23.json\", \"w\")\n",
    "matura23File.write(matura23_str)\n",
    "matura23File.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
